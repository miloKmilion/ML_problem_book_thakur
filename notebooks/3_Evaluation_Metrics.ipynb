{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Evaluation Metrics\n",
    "\n",
    "When comes to ML problems, there will be a lot odf different metrics in the real world. Sometimes, new mtrics are are created to solve a bussiness case.\n",
    "\n",
    "Some metrics used in the supervised **classification** learning context are:\n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1 Score\n",
    "* Area Under the ROC or curve, (AUC)\n",
    "* LogLoss\n",
    "* Average precision\n",
    "* Mean average precision\n",
    "\n",
    "Some metrics used in the supervised **Regression** learning context are:\n",
    "* Mean absolute error (MAE)\n",
    "* Mean Squared error (MSE)\n",
    "* Root mean squared error (RMSE)\n",
    "* Root mean squared logarithmic error (RMSLE)\n",
    "* Mean absolute percentage error (MAPE)\n",
    "* R^2^\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Example:\n",
    "Supposing we have a **binary classification problem.**\n",
    "\n",
    "Classifying X-ray images from lungs, some of them have collapsed lungs vs normal ones.\n",
    "\n",
    "Task: To build a classifier that given a chest X-ray image can detect if is pneumotorax.\n",
    "\n",
    "Assumptions: Equal numbers of samples, being 100 positive vs 100 negatives, then a total of 200 images.\n",
    "\n",
    "1. Divide the data described in 2 sets of 100 images each -> Training and validation set, having a total of 50 positives and 50 negative samples.\n",
    "\n",
    "*Having an equal number of positive and negative samples in a binary classification metric --> Accuracy, precision, recall and f1*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Accuracy:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate accuracy\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: accuracy store\n",
    "    \"\"\"\n",
    "    # Initialize a simple counter for correct predictions\n",
    "    correct_counter = 0\n",
    "    # Loop over all elements in y_true and y_pred together\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == yp:\n",
    "            # If prediction is equal to truth, increase the counter.\n",
    "            correct_counter += 1\n",
    "\n",
    "    # Return accuracy\n",
    "    # Which is correct predictions over the number of samples\n",
    "    return correct_counter / len(y_true)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Precision\n",
    "If the dataset changes as: 180 normal images vs 20 with pneumothorax. We need to create a training and validation set with the same\n",
    "ratio of positive to negative targets.\n",
    "\n",
    "In each set 90 normal vs 10 pneumothorax images.\n",
    "\n",
    "it is necessary to learn certain concepts needed now that we assume the normal samples = 0 and pneumothorax = 1\n",
    "\n",
    "##### True positive (TP)\n",
    "Given an image, if the model predicts the correct one having pneumothorax and the actual target also predicts the correct answer then is a **True Positive**\n",
    "\n",
    "##### True Negative (TN)\n",
    "Given an image, if the model predicts that the image does not have pneumothorax and the target also says that is a non-pneumothorax then is a **True Negative**\n",
    "\n",
    "##### False positive (FP)\n",
    "Given an image, if the model predicts pneumothorax and the actual target image is a non-pneumothorax then is a **False Positive**\n",
    "\n",
    "##### False negative (FN)\n",
    "Given an image, if the model predicts non-pneumothorax and the actual target image is pneumothorax then is a **False Negative**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def true_positive(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate True Positives\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of true positives\n",
    "    \"\"\"\n",
    "    #Initialize\n",
    "    tp = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            tp += 1\n",
    "\n",
    "    return tp\n",
    "\n",
    "\n",
    "def true_negative(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate True Negatives\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of true negatives\n",
    "    \"\"\"\n",
    "    #Initialize\n",
    "    tn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 0:\n",
    "            tn += 1\n",
    "\n",
    "    return tn\n",
    "\n",
    "def false_positive(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate False Positives\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of False positives\n",
    "    \"\"\"\n",
    "    #Initialize\n",
    "    fp = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 1:\n",
    "            fp += 1\n",
    "\n",
    "    return fp\n",
    "\n",
    "def false_negative(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate False negatives\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of False Negatives\n",
    "    \"\"\"\n",
    "    #Initialize\n",
    "    fn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 0:\n",
    "            fn += 1\n",
    "\n",
    "    return fn\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "### Implementing accuracy score using the functions defined before\n",
    "def accuracy_v2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate accuracy using tp/tn/fp/fn\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values.\n",
    "    :return: accuracy score.\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true,y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "\n",
    "    accuracy_score = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return accuracy_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0.625"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]\n",
    "\n",
    "accuracy(l1, l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0.625"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_v2(l1, l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.625"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.accuracy_score(l1, l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Precision\n",
    "defined as\n",
    "*Precision = TP / (TP + FP)*\n",
    "\n",
    "By implementing TP, TN, FP and FN, then is easy to implement precision\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate precision\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values.\n",
    "    :return: Precision Score.\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    precision_score = tp / (tp + fp)\n",
    "    return precision_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6666666666666666"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(l1, l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Recall\n",
    "Recall indicates the number of positive samples identified correctly.\n",
    "\n",
    "* *Recall = TP / (TP + FN)*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Recall\n",
    "    :param y_true: list of true values\n",
    "    :param y_pred: list of predicted values.\n",
    "    :return: Precision Score.\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    recall_score = tp / (tp + fn)\n",
    "    return recall_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(l1, l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For a good model, precision and recall values should be high. In the example above, recall is high but precision is low which indicates that our model indicates a lot of false positives\n",
    "but fewer false negatives.\n",
    "\n",
    "Most of the models predict a probability, and when predict the threshold is set to 0.5. This is not always ideal, and depending on the threshold the value of recall and precision will change\n",
    "drastically. For each threshold chosen it is necessary to calculate precision and recall values, and plotting that set of values. That plot is known as **precision-recall curve**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### F1 score\n",
    "It is a metric that combines both precision and recall. It is defined as a simple weighted average (harmonic mean) of precision and recall.\n",
    "\n",
    "Being Precision = P and Recall = R then *F1 = 2PR / (P + R)*\n",
    "That can be converted into: *F1 = 2TP /  (2TP + FP + FN)*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate the F1 Score.\n",
    "    :param y_true: List of true values\n",
    "    :param y_pred: List of predicted values\n",
    "    :return: F1 Score\n",
    "    \"\"\"\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "\n",
    "    f1_score = 2 * p * r / (p + r)\n",
    "    return f1_score\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5714285714285715"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(l1, l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5714285714285715"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(l1, l2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Instead of looking at precision and recall individually the F1 score should be used. This score also ranges from 0 to 1 .\n",
    "* When dealing with skewed targets in datasets, the F1 score is more reliable than accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TPR - True Positive Rate\n",
    "It is equivalent to recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def tpr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate the TPR.\n",
    "    :param y_true: List of true values\n",
    "    :param y_pred: List of predicted values\n",
    "    :return: tpr/recall Score\n",
    "    \"\"\"\n",
    "    return recall(y_true, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### FPR - False Positive rate.\n",
    "It is defined by *FPR = FP / (TN + FP)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def fpr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate the FPR.\n",
    "    :param y_true: List of true values\n",
    "    :param y_pred: List of predicted values\n",
    "    :return: fpr\n",
    "    \"\"\"\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "\n",
    "    fpr_score = fp / (tn + fp)\n",
    "    return fpr_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1 - FPR is known as specificity or True Negative Rate or TNR."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "tpr_list = []\n",
    "fpr_list = []\n",
    "\n",
    "# Actual targets\n",
    "y_true = [0,0,0,0,1,0,1,0,0,1,0,1,0,0,1]\n",
    "\n",
    "# Predicted probabilities of a sample being 1\n",
    "y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05, 0.9, 0.5, 0.3, 0.66, 0.3, 0.2, 0.85, 0.15, 0.99]\n",
    "\n",
    "# handmade thresholds\n",
    "thresholds = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.99, 1]\n",
    "\n",
    "# loop over all thresholds\n",
    "for thresh in thresholds:\n",
    "    # Calculate the predictions for a given threshold\n",
    "    tem_pred = [1 if x >= thresh else 0 for x in y_pred]\n",
    "    # calculate tpr\n",
    "    tem_tpr = tpr(y_true, tem_pred)\n",
    "    # calculate fpr\n",
    "    tem_fpr = fpr(y_true, tem_pred)\n",
    "    # append tpr and fpr to lists\n",
    "    tpr_list.append(tem_tpr)\n",
    "    fpr_list.append(tem_fpr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9, 0.7, 0.6, 0.3, 0.3, 0.2, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0]\n",
      "[1.0, 1.0, 1.0, 0.8, 0.8, 0.8, 0.8, 0.6, 0.6, 0.4, 0.4, 0.2, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(fpr_list)\n",
    "print(tpr_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 700x700 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import manifold\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.fill_between(fpr_list, tpr_list, alpha=0.4)\n",
    "plt.plot(fpr_list, tpr_list, lw=3)\n",
    "plt.xlim(0, 1.0)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.xlabel('FPR', fontsize=15)\n",
    "plt.ylabel('TPR', fontsize=15)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "The curve above is known as the **Receiver Operating Characteristic (ROC)**. And calculating the area under the ROC curve is equivalent to another metric\n",
    "used when the dataset studied has skewed binary targets.\n",
    "\n",
    "The metric mentioned is known as the **Area Under the Curve (AUC)**. The values range from 0 to 1.\n",
    "\n",
    "* **AUC = 1** implies that the model is perfect. Usually, it means that there was a mistake with validation, and it should revisit the data processing and validation\n",
    "pipeline.\n",
    "* **AUC = 0** implies that the model is very bad. Try inverting the probabilities for the predictions, e.g., if the probability for a predicted class is p, reconsider\n",
    "to substituting it for 1 - p. This AUC indicates thaT there is some problem with the validation or data processing.\n",
    "* **AUC = 0.5** implies that the predictions are random. So, for any binary classification problem, if  predicts all targets as 0.5.\n",
    "\n",
    "AUC values between 0 and 0.5 imply that the model is worse than random.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
